{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain==0.2.16 langchain-openai ragas==0.1.14 pandas langchain-qdrant qdrant-client python-dotenv langchain-anthropic langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv('../app/.env')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "if not OPENAI_API_KEY or not ANTHROPIC_API_KEY:\n",
    "    print(\"Error retrieving API keys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load our document corpus from a file. (fetch_data.ipynb can be used to generate the file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 216 docs\n"
     ]
    }
   ],
   "source": [
    "myfile = \"source_documents.json\"\n",
    "\n",
    "import json\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Load JSON data\n",
    "with open(myfile, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Convert JSON data into a list of LangChain Document objects\n",
    "docs = [\n",
    "    Document(page_content=item[\"page_content\"], metadata=item[\"metadata\"])\n",
    "    for item in data\n",
    "]\n",
    "\n",
    "print(f\"loaded {len(docs)} docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline chunking strategy: Fixed width, 1500 chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(docs): 216, len(split_docs):1349\n",
      "page_content='alzheimer's disease and dementia | alzheimer's disease and dementia | cdc     alzheimer's disease and dementia alzheimer's basics learn about signs and symptoms of alzheimer's disease and who is affected. aug. 15, 2024 dementia basics learn about common types of dementia, signs and symptoms, and risk factors. aug. 17, 2024 signs and symptoms of alzheimer's learn how to recognize the early signs of alzheimer's disease. signs and symptoms of dementia learn what early signs and symptoms of dementia to look out for. tools and resources find a variety of resources about alzheimer’s disease and healthy aging. reducing risk learn what lifestyle behaviors can reduce the risk of developing dementia. additional topics healthy aging at any age information to help you stay healthy and strong throughout your life. sept. 3, 2024 alzheimer's disease program evidence-based, scientific information to educate, inform, and assist translating research into publ... july 2, 2024 caregiving find information about caregiving, self-care, and care plan creation. sept. 3, 2024 healthy aging data national and state level cdc data for older adults on a range of health and well-being key indicators. aug. 27, 2024 alzheimer's disease and dementia dementia is not a specific disease. it is a general term for having trouble remembering, thinking, or making decisions that affect everyday activities. view all for everyone dementia basics signs and symptoms of dementia reducing risk campaign public health public' metadata={'url': 'https://www.cdc.gov/alzheimers-dementia', 'title': \"Alzheimer's Disease and Dementia | Alzheimer's Disease and Dementia | CDC\", 'chunk_id': 0}\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,       \n",
    "    chunk_overlap=150,     \n",
    ")\n",
    "\n",
    "split_docs = []\n",
    "\n",
    "for doc in docs:\n",
    "\n",
    "    splits = text_splitter.split_text(doc.page_content)\n",
    "    for i,split in enumerate(splits):\n",
    "        metadata_with_chunk = {**doc.metadata, \"chunk_id\": i}\n",
    "            \n",
    "        # Create the document with the updated metadata\n",
    "        split_doc = Document(page_content=split, metadata=metadata_with_chunk)\n",
    "        split_docs.append(split_doc)\n",
    "\n",
    "print(f\"len(docs): {len(docs)}, len(split_docs):{len(split_docs)}\")\n",
    "print(split_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embedding_model = \"text-embedding-3-large\"\n",
    "openai_embeddings = OpenAIEmbeddings(\n",
    "    model=embedding_model,\n",
    "    openai_api_key=OPENAI_API_KEY  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216/216 [03:01<00:00,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(docs): 216, len(semantic_split_docs):1074\n",
      "page_content='alzheimer's disease and dementia | alzheimer's disease and dementia | cdc     alzheimer's disease and dementia alzheimer's basics learn about signs and symptoms of alzheimer's disease and who is affected. aug. 15, 2024 dementia basics learn about common types of dementia, signs and symptoms, and risk factors. aug. 17, 2024 signs and symptoms of alzheimer's learn how to recognize the early signs of alzheimer's disease. signs and symptoms of dementia learn what early signs and symptoms of dementia to look out for. tools and resources find a variety of resources about alzheimer’s disease and healthy aging. reducing risk learn what lifestyle behaviors can reduce the risk of developing dementia. additional topics healthy aging at any age information to help you stay healthy and strong throughout your life. sept. 3, 2024 alzheimer's disease program evidence-based, scientific information to educate, inform, and assist translating research into publ... july 2, 2024 caregiving find information about caregiving, self-care, and care plan creation. sept. 3, 2024 healthy aging data national and state level cdc data for older adults on a range of health and well-being key indicators. aug.' metadata={'url': 'https://www.cdc.gov/alzheimers-dementia', 'title': \"Alzheimer's Disease and Dementia | Alzheimer's Disease and Dementia | CDC\", 'chunk_id': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from tqdm import tqdm\n",
    "\n",
    "semantic_text_splitter = SemanticChunker(openai_embeddings,\n",
    "    breakpoint_threshold_type=\"percentile\")\n",
    "\n",
    "semantic_split_docs = []\n",
    "\n",
    "for doc in tqdm(docs):\n",
    "\n",
    "    splits = semantic_text_splitter.split_text(doc.page_content)\n",
    "    for i,split in enumerate(splits):\n",
    "        metadata_with_chunk = {**doc.metadata, \"chunk_id\": i}\n",
    "            \n",
    "        # Create the document with the updated metadata\n",
    "        semantic_split_doc = Document(page_content=split, metadata=metadata_with_chunk)\n",
    "        semantic_split_docs.append(semantic_split_doc)\n",
    "\n",
    "print(f\"len(docs): {len(docs)}, len(semantic_split_docs):{len(semantic_split_docs)}\")\n",
    "print(semantic_split_docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add the docs to a vector store. Make sure qdrant is running first (see README.md for more details). We can create it once and re-use it after that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collections=[CollectionDescription(name='PottyTraining'), CollectionDescription(name='DementiaCare_Semantic'), CollectionDescription(name='DementiaCare_Fixed')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "url=\"http://localhost:6333\"\n",
    "\n",
    "client = QdrantClient(url=url, prefer_grpc=True)\n",
    "print(client.get_collections())\n",
    "\n",
    "# Delete any existing collections here, otherwise the code below will extend rather than overwrite them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name_fixed = \"DementiaCare_Fixed\"\n",
    "collection_name_semantic = \"DementiaCare_Semantic\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client.delete_collection(collection_name_fixed)\n",
    "try:\n",
    "    qdrant_vector_store_fixed = QdrantVectorStore.from_documents(\n",
    "        split_docs,\n",
    "        openai_embeddings,\n",
    "        url=url,\n",
    "        prefer_grpc=True,\n",
    "        collection_name=collection_name_fixed,\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Encountered error creating vector store: {e}\")\n",
    "\n",
    "if qdrant_vector_store_fixed: print(f\"Created vector store {collection_name_fixed}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qdrant_vector_store_fixed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered error creating vector store: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m qdrant_vector_store_fixed: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated vector store \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcollection_name_semantic\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(client\u001b[38;5;241m.\u001b[39mget_collections())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'qdrant_vector_store_fixed' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "client.delete_collection(collection_name_semantic)\n",
    "try:\n",
    "    qdrant_vector_store_semantic = QdrantVectorStore.from_documents(\n",
    "        semantic_split_docs,\n",
    "        openai_embeddings,\n",
    "        url=url,\n",
    "        prefer_grpc=True,\n",
    "        collection_name=collection_name_semantic,\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Encountered error creating vector store: {e}\")\n",
    "\n",
    "if qdrant_vector_store_semantic: print(f\"Created vector store {collection_name_semantic}\")\n",
    "\n",
    "print(client.get_collections())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the collections already exist, just load them\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "url=\"http://localhost:6333\"\n",
    "\n",
    "\n",
    "store_fixed = QdrantVectorStore.from_existing_collection(\n",
    "    embedding=openai_embeddings,\n",
    "    collection_name=collection_name_fixed,\n",
    "    url=url\n",
    ")\n",
    "\n",
    "store_semantic = QdrantVectorStore.from_existing_collection(\n",
    "    embedding=openai_embeddings,\n",
    "    collection_name=collection_name_semantic,\n",
    "    url=url\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up RAGAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_precision,\n",
    "    context_recall\n",
    ")\n",
    "RAGAS_METRICS = [ faithfulness, answer_relevancy, context_precision, context_recall ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='dementia caregivers, though the phenomenon appears to be more severe or extreme for dementia caregivers. Further, dementia caregivers more often experience emotional stress and physical strain than do non-dementia caregivers—a situation that contributes to the disproportionately worsening health among dementia caregivers. Prior research has documented the ways caregiving can affect caregivers’ health and well-being. Caregiving has been associated with higher levels depression and anxiety, compromised immune function, and increased mortality.17 These negative health impacts mean that caregiving is a crucially important public health issue—caregivers’ health suffers under the pressure of caregiving responsibilities, and such decline in health compromises the caregiver’s ability to provide care. This problem is particularly pressing for dementia caregivers, as health impacts are worse and loved ones rely on these caregivers for more daily assistance. Therefore, it is critical to improve the resources and help available to dementia caregivers so that they can easily and adequately care for their loved ones and for themselves. 17 Centers for Disease Control and Prevention and the Kimberly-Clark Corporation, “Assuring Healthy Caregivers, A Public Health Approach to Translating Research into Practice: The RE-AIM Framework,” Kimberly-Clark Corporation, Neenah, WI, 2008.' metadata={'url': 'https://www.caregiving.org/wp-content/uploads/2020/05/Dementia-Caregiving-in-the-US_February-2017.pdf', 'chunk_id': 47, '_id': '54fdf9f9-aede-4958-aef3-abaf7636c466', '_collection_name': 'DementiaCare_Fixed'}\n",
      "page_content='significantly fewer than working female dementia caregivers (65 percent)\n",
      "27 Figure 25: Work Impacts Due to Caregiving Q34: As a result of caregiving, did you ever experience any of these things at work? Financial Impacts of Caregiving Nearly one in five dementia caregivers (19 percent) reports high financial strain due to caring for their loved one, similar to the figure for non-dementia caregivers (17 percent). As mentioned previously, 28 percent say it is difficult to find affordable services in their loved one’s area. In response to three different proposals intended to provide financial relief for caregivers, dementia caregivers tended to prefer a tax credit (33 percent) or programs that include a stipend for at least some of the hours they provide care (28 percent). Figure 26: Proposals to Provide Financial Aid to Caregivers Q47a: Below are some ways that people are proposing to help caregivers financially. Which one would you find/have found most helpful? Dementia Caregiver (n=372) Non-Dementia Caregiver (n=963) Income tax credit to caregivers, to help offset the cost of care 33% 29% Program where caregivers could be paid for at least some of the hours they provide care 28% 31% Partially paid leave of absence from work, for employed caregiversa 12% 11% Not sure 26% 29% a Support for partially paid work leave was similar among dementia caregivers who were employed (13 percent) and not employed (11 percent).' metadata={'url': 'https://www.caregiving.org/wp-content/uploads/2020/05/Dementia-Caregiving-in-the-US_February-2017.pdf', 'chunk_id': 58, '_id': '40db1829-e523-4d3d-a460-98e409eeb8a9', '_collection_name': 'DementiaCare_Fixed'}\n",
      "page_content='2 Considering all of the responsibilities that dementia caregivers often shoulder, it is of no surprise that the Burden of Care Index2 shows them as one of the more burdened groups of caregivers. Nearly half of dementia caregivers are in a high-burden situation. Dementia caregivers are not the most-burdened group—for example, cancer caregivers are more likely to be in high-burden care relationships (62 percent).3 However, whereas cancer caregiver relationships are short and episodic, dementia caregiver relationships tend to be longer: nearly seven in ten (69 percent) dementia caregivers have provided care for more than a year, and three in ten have provided care for more than five years. This high burden of care over a longer period can take a significant mental and physical toll on dementia caregivers. Nearly half of dementia caregivers say providing care is emotionally stressful, and three in ten say that providing care often involves physical strain. Ultimately, this physical and emotional stress appears to have a negative impact on the health of many dementia caregivers. About four in ten (42 percent) say their health is “excellent” or “very good”—statistically significantly lower than the share among non-dementia caregivers (50 percent). Alarmingly, dementia caregivers are nearly twice as likely to say that their health has gotten worse as a result of their caregiving responsibilities. More than one in three dementia caregivers says their health has declined (35' metadata={'url': 'https://www.caregiving.org/wp-content/uploads/2020/05/Dementia-Caregiving-in-the-US_February-2017.pdf', 'chunk_id': 10, '_id': '51850131-5aff-4534-a387-e41151b647b7', '_collection_name': 'DementiaCare_Fixed'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "mmr_retriever_fixed = store_fixed.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={'k': 10, 'lambda_mult': 0.1}\n",
    ")\n",
    "similarity_retriever_fixed = store_fixed.as_retriever(k=10)\n",
    "ensemble_retriever_fixed = EnsembleRetriever(retrievers=[mmr_retriever_fixed,similarity_retriever_fixed])\n",
    "\n",
    "results = ensemble_retriever_fixed.invoke(\"How does stress impact dementia caregivers?\")\n",
    "for result in results[:3]: print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "page_content='Levine, and S. Samis, “Home Alone: Family Caregivers Providing Complex Chronic Care,” AARP Public Policy Institute & United Hospital Fund, 2012. 2 Considering all of the responsibilities that dementia caregivers often shoulder, it is of no surprise that the Burden of Care Index2 shows them as one of the more burdened groups of caregivers. Nearly half of dementia caregivers are in a high-burden situation. Dementia caregivers are not the most-burdened group—for example, cancer caregivers are more likely to be in high-burden care relationships (62 percent).3 However, whereas cancer caregiver relationships are short and episodic, dementia caregiver relationships tend to be longer: nearly seven in ten (69 percent) dementia caregivers have provided care for more than a year, and three in ten have provided care for more than five years. This high burden of care over a longer period can take a significant mental and physical toll on dementia caregivers. Nearly half of dementia caregivers say providing care is emotionally stressful, and three in ten say that providing care often involves physical strain. Ultimately, this physical and emotional stress appears to have a negative impact on the health of many dementia caregivers. About four in ten (42 percent) say their health is “excellent” or “very good”—statistically significantly lower than the share among non-dementia caregivers (50 percent). Alarmingly, dementia caregivers are nearly twice as likely to say that their health has gotten worse as a result of their caregiving responsibilities. More than one in three dementia caregivers says their health has declined (35 percent), versus just one in five non-dementia caregivers. Many dementia caregivers report that they receive help. Dementia caregivers, more than non-dementia caregivers, are often one part of a larger care team, and they receive more paid and unpaid assistance than non-dementia caregivers. Four in ten dementia caregivers are the sole unpaid caregiver for their loved one. Nearly half of dementia caregivers say their loved one has received help from aides, housekeepers, or other paid help (45 percent), including 43 percent of sole unpaid dementia caregivers. More than one in four has used a respite service (27 percent). However, not all dementia caregivers can find resources when they need them: 28 percent say they find it difficult to get affordable services in their loved one’s community. Six in ten dementia caregivers were employed in the last year while they provided care to their loved one. Employed dementia caregivers work an average of 34.9 hours per week while caregiving, and more than half (57 percent) work full time. Seven in ten employed dementia caregivers (70 percent) say their supervisor was aware of their caregiving situation. Nonetheless, many employed caregivers struggle to balance their job and their caregiving responsibilities. Two in three employed dementia caregivers report that their caregiving responsibilities affected their work in some way (statistically significantly higher than the 59 percent of non-dementia caregivers). 2 “Burden of Care” is an index that is based on the number of hours of care provided by the caregiver, the number of ADLs performed, and the number of IADLs performed. Points are assigned for each of them; ultimately, these points are consolidated into three burden categories: low (values 1–2), medium (3), and high (values 4–5). See Caregiving in the U.S. 2015 Appendix B, Detailed Methodology for the details of creating the index (www.caregiving.org/caregiving2015). 3 G.G.' metadata={'chunk_id': 4, 'url': 'https://www.caregiving.org/wp-content/uploads/2020/05/Dementia-Caregiving-in-the-US_February-2017.pdf', '_id': '08ae7c19-83e1-419c-bb50-b2a1646b4d35', '_collection_name': 'DementiaCare_Semantic'}\n",
      "page_content='the emotional impact of living with memory loss | alzheimer's society the emotional impact of living with memory loss everyone reacts differently to memory loss. it can cause a range of emotions in both the person with dementia and those supporting them. memory loss and dementia you are here: the emotional impact of living with memory loss therapy and approaches for memory loss support memory loss and dementia – useful organisations supporting a person with memory loss save this information get a copy order by post helping the person with memory loss to manage their emotions some people with dementia may not seem troubled by their memory loss, while others may find it frustrating and upsetting. the person may lose self-confidence and be embarrassed by their difficulties. they may begin to withdraw from social situations or stop doing things they usually do. memory loss can also lead to people misplacing items that they then might think others have moved or stolen. this can sometimes cause anger and mistrust between the person with dementia and those around them. see ‘ dementia and hiding, hoarding or losing things ’ for more advice. making decisions for someone with dementia read more about assisting somebody with dementia to make decisions and when it's appropriate. making decisions it can be helpful to be aware of these difficulties and find ways to provide support. the following suggestions might help: if the person is ready to, encourage them to talk about how they are feeling. if they are frustrated or upset because of their memory difficulties, it can help to talk through some of the issues with them. look for different ways to manage some of the day-to-day problems they are having. for suggestions, see practical tips for supporting someone with memory loss . if the person is worried about the future, try to understand their concerns and help them focus on the present. think of what they can still do and encourage or support them to continue doing these things. there are approaches for supporting people with memory loss which can help rebuild confidence. encourage the person to continue spending time with other people and to take part in meaningful activities that do not rely as much on memory, such as word or number games. if the person is frustrated because of their memory problems, they may get distressed or agitated. in these cases, it may be best to gently change the conversation or activity. for more information on changes in behaviour and tips on how to cope with these see changes in behaviour . managing your emotions as a carer for someone with memory loss if you are supporting a person with dementia who is living with memory loss, you are also likely to feel a range of emotions. for example, if the person is recalling earlier happy memories, it can sometimes be nice to reminisce together. this can make you feel closer to the person. but it can also be difficult to care for someone with memory loss. for example, you may feel embarrassed if the person forgets who someone is, or if they no longer remember how to carry out a task. or you might feel sad that the person has forgotten memories that you share with them. advice guilt and dementia: how to manage guilty feelings as a carer advice feelings of guilt can be difficult to deal with as a carer of somebody living with dementia. read our advice to help identify and manage guilty feelings. feelings of guilt can be difficult to deal with as a carer of somebody living with dementia. read our advice to help identify and manage guilty feelings. ... 25 may 2023 it can be tiring and frustrating to be asked the same question many times, and this might make you feel guilty . you may also feel unsure about what you can talk about with the person without relying too much on their memory. it is natural to feel these emotions when caring for someone with memory loss. reminding yourself that the person’s difficulties are because of their dementia may help you to deal with these feelings. it is also worth reminding yourself that, by supporting the person, you are making a positive difference to their life. when caring for someone else, the needs of that person often come before your own. this can make it difficult for you take care of yourself. however, it is just as important to look after your own physical and mental health . if you are trying to process how the person’s memory loss is making you feel, you may find a talking therapy useful. these will allow you to explore your feelings in private. to get in touch with a therapist, you can speak to your gp or you can find a private therapist by contacting the british association for counselling and psychotherapy . carers: looking after yourself find out more about accessing support and looking after yourself when caring for somebody else. support for carers think this page could be useful to someone? share it: share this page on facebook.' metadata={'url': 'https://www.alzheimers.org.uk/about-dementia/symptoms-and-diagnosis/symptoms/emotions-memory-loss', 'chunk_id': 0, 'title': \"The emotional impact of living with memory loss | Alzheimer's Society\", '_id': '95a74bb3-6840-4864-a22d-e5fde90053ff', '_collection_name': 'DementiaCare_Semantic'}\n",
      "page_content='(2012) “Home Aone: Family Caregivers Providing Complex Chronic Car” AARP Public Policy Institute & United Hospital Fund. 17 Dementia caregivers are twice as likely to say that doing medical/nursing tasks is difficult (22 percent versus 11 percent of non-dementia caregivers; see Figure 11). Figure 11: Difficulty of Performing Medical/Nursing Tasks N4: How difficult is/was it for you to do the medical/nursing tasks that are/were required to help your [relation]? Dementia caregivers’ lack of prior preparation and difficulty doing these complex medical/nursing tasks suggest a need for additional training and support. Some ways that dementia caregivers would prefer to learn medical/nursing tasks are to work in person with a qualified teacher or other professional. Most say they would like to have a qualified person show them how to do medical/nursing tasks (67 percent) or do it themselves while a qualified person watches (60 percent). Fewer say they would want videos on demand or written instructions. Figure 12: Preferred Way of Learning Medical/Nursing Tasks N8: If you had to learn how to do a medical/nursing tasks, how would you prefer to learn? 18 High Care Burden over Longer Period Endangers Caregiver Health Considering all of the responsibilities dementia caregivers shoulder, it should come as no surprise that the Burden of Care Index13 scores them as one of the more burdened groups of caregivers. Nearly half of dementia caregivers are in a high-burden situation, and dementia caregivers have a significantly higher average burden than do non-\n",
      "dementia caregivers. Figure 13: Burden of Care Index Dementia caregivers are not the most-burdened group—for example, cancer caregivers are more likely to be in high-burden care relationships (62 percent).14 However, where cancer caregiver relationships are short and episodic, dementia care relationships tend to be longer in duration. Nearly seven in ten (69 percent) dementia caregivers have provided care for more than a year, and three in ten have provided care for more than five years; both rates are significantly higher than those among non-dementia caregivers. More than one in seven dementia caregivers has provided care for over a decade (see Figure 14, next page). 13 “Burden of Care” is an index based on the number of hours of care provided by the caregiver, the number of Activities of Daily Living performed, and the number of Instrumental Activities of Daily Living. Points are assigned for each of these, and ultimately, these points are consolidated into three burden categories: low (values 1 and 2), medium (3), and high (values 4 and 5). See Caregiving in the U.S. 2015 Appendix B, Detailed Methodology for the details of creating the index. 14 Hunt, G.' metadata={'chunk_id': 8, 'url': 'https://www.caregiving.org/wp-content/uploads/2020/05/Dementia-Caregiving-in-the-US_February-2017.pdf', '_id': '0f8c849b-4673-4bd5-bb6f-702e882901eb', '_collection_name': 'DementiaCare_Semantic'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mmr_retriever_semantic = store_semantic.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={'k': 10, 'lambda_mult': 0.1}\n",
    ")\n",
    "similarity_retriever_semantic = store_semantic.as_retriever(k=10)\n",
    "ensemble_retriever_semantic = EnsembleRetriever(retrievers=[mmr_retriever_semantic,similarity_retriever_semantic])\n",
    "\n",
    "results = ensemble_retriever_semantic.invoke(\"How does stress impact dementia caregivers?\")\n",
    "print(\"\\n\")\n",
    "for result in results[:3]: print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it out in a simple RAG chain: Create a prompt, initialize an LLM, and then use the retriever in a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "RAG_PROMPT_TEMPLATE = \"\"\"\n",
    "You are a helpful assistant. Answer the question based on the context. If you don't know, say you don't know.\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "<question>\n",
    "{query}\n",
    "<question>\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = PromptTemplate.from_template(RAG_PROMPT_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "haiku_model_id = \"claude-3-haiku-20240307\" # cheaper and better to use for prototyping, although we'll use 3.5 in our app\n",
    "claude_3_5_sonnet_model_id = \"claude-3-5-sonnet-20240620\"\n",
    "\n",
    "llm = ChatAnthropic(\n",
    "    model=haiku_model_id,    \n",
    "    anthropic_api_key=ANTHROPIC_API_KEY,\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "async def gen_rag_responses(rag_chain) -> Dataset:\n",
    "    \"\"\"Wrapper function to run a RAG chain against a test dataset and generate/store responses\"\"\"\n",
    "    test_df = pd.read_csv(\"ragas_test_data.csv\")\n",
    "\n",
    "    test_questions = test_df[\"question\"].to_list()\n",
    "    test_gt = test_df[\"ground_truth\"].to_list()\n",
    "    print(\"read test questions\")\n",
    "\n",
    "    answers = []\n",
    "    contexts = []\n",
    "\n",
    "    print(\"generating responses\")\n",
    "    for question in tqdm_asyncio(test_questions,desc=\"Processing Questions\"):\n",
    "        response = await rag_chain.ainvoke({\"query\" : question})\n",
    "        answers.append(response[\"response\"].content)\n",
    "        contexts.append([context.page_content for context in response[\"context\"]])\n",
    "\n",
    "    # Put in huggingface dataset format and save it for later re-use\n",
    "    response_dataset = Dataset.from_dict({\n",
    "        \"question\" : test_questions,\n",
    "        \"answer\" : answers,\n",
    "        \"contexts\" : contexts,\n",
    "        \"ground_truth\" : test_gt\n",
    "    })\n",
    "\n",
    "    return response_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from ragas import evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read test questions\n",
      "generating responses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Questions: 100%|██████████| 30/30 [01:37<00:00,  3.26s/it]\n",
      "Evaluating: 100%|██████████| 120/120 [01:09<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'faithfulness': 0.9507, 'answer_relevancy': 0.7835, 'context_precision': 0.8676, 'context_recall': 0.9200}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# standard RAG that passes the context through\n",
    "fixed_similarity_rag_chain = (\n",
    "    {\"context\": itemgetter(\"query\") | similarity_retriever_fixed | (lambda docs: docs[:4]), \"query\": itemgetter(\"query\")} \n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
    ")\n",
    "\n",
    "response_dataset = await gen_rag_responses(fixed_similarity_rag_chain)\n",
    "\n",
    "from ragas import evaluate\n",
    "\n",
    "results = evaluate(response_dataset, \n",
    "                   RAGAS_METRICS)\n",
    "\n",
    "# Check out the results\n",
    "print(results)\n",
    "results_df = pd.DataFrame([results])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read test questions\n",
      "generating responses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Questions: 100%|██████████| 30/30 [01:47<00:00,  3.59s/it]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'evaluate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m fixed_mmr_rag_chain \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      2\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: itemgetter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m|\u001b[39m mmr_retriever_fixed \u001b[38;5;241m|\u001b[39m (\u001b[38;5;28;01mlambda\u001b[39;00m docs: docs[:\u001b[38;5;241m4\u001b[39m]), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: itemgetter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m)} \n\u001b[1;32m      3\u001b[0m     \u001b[38;5;241m|\u001b[39m RunnablePassthrough\u001b[38;5;241m.\u001b[39massign(context\u001b[38;5;241m=\u001b[39mitemgetter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;241m|\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m: rag_prompt \u001b[38;5;241m|\u001b[39m llm, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: itemgetter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m)}\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      7\u001b[0m response_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m gen_rag_responses(fixed_mmr_rag_chain)\n\u001b[0;32m----> 8\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m(response_dataset, \n\u001b[1;32m      9\u001b[0m                    RAGAS_METRICS)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Check out the results\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluate' is not defined"
     ]
    }
   ],
   "source": [
    "fixed_mmr_rag_chain = (\n",
    "    {\"context\": itemgetter(\"query\") | mmr_retriever_fixed | (lambda docs: docs[:4]), \"query\": itemgetter(\"query\")} \n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
    ")\n",
    "\n",
    "response_dataset = await gen_rag_responses(fixed_mmr_rag_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 120/120 [01:02<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'faithfulness': 0.9091, 'answer_relevancy': 0.9486, 'context_precision': 0.8074, 'context_recall': 0.8522}\n"
     ]
    }
   ],
   "source": [
    "results = evaluate(response_dataset, \n",
    "                   RAGAS_METRICS)\n",
    "\n",
    "# Check out the results\n",
    "print(results)\n",
    "results_df = pd.DataFrame([results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read test questions\n",
      "generating responses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Questions: 100%|██████████| 30/30 [01:43<00:00,  3.44s/it]\n",
      "Evaluating: 100%|██████████| 120/120 [00:53<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'faithfulness': 0.9586, 'answer_relevancy': 0.8842, 'context_precision': 0.8537, 'context_recall': 0.9133}\n"
     ]
    }
   ],
   "source": [
    "fixed_ensemble_rag_chain = (\n",
    "    {\"context\": itemgetter(\"query\") | ensemble_retriever_fixed | (lambda docs: docs[:4]), \"query\": itemgetter(\"query\")} \n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
    ")\n",
    "\n",
    "response_dataset = await gen_rag_responses(fixed_ensemble_rag_chain)\n",
    "results = evaluate(response_dataset, \n",
    "                   RAGAS_METRICS)\n",
    "\n",
    "# Check out the results\n",
    "print(results)\n",
    "results_df = pd.DataFrame([results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read test questions\n",
      "generating responses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Questions:   0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Questions: 100%|██████████| 30/30 [01:40<00:00,  3.36s/it]\n",
      "Evaluating: 100%|██████████| 120/120 [01:06<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'faithfulness': 0.9521, 'answer_relevancy': 0.8805, 'context_precision': 0.8713, 'context_recall': 0.9272}\n"
     ]
    }
   ],
   "source": [
    "semantic_similarity_rag_chain = (\n",
    "    {\"context\": itemgetter(\"query\") | similarity_retriever_semantic | (lambda docs: docs[:4]), \"query\": itemgetter(\"query\")} \n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
    ")\n",
    "\n",
    "response_dataset = await gen_rag_responses(semantic_similarity_rag_chain)\n",
    "results = evaluate(response_dataset, \n",
    "                   RAGAS_METRICS)\n",
    "\n",
    "# Check out the results\n",
    "print(results)\n",
    "results_df = pd.DataFrame([results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read test questions\n",
      "generating responses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Questions:   0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Questions: 100%|██████████| 30/30 [01:56<00:00,  3.87s/it]\n",
      "Evaluating: 100%|██████████| 120/120 [00:48<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'faithfulness': 0.9500, 'answer_relevancy': 0.8781, 'context_precision': 0.8185, 'context_recall': 0.8211}\n"
     ]
    }
   ],
   "source": [
    "semantic_mmr_rag_chain = (\n",
    "    {\"context\": itemgetter(\"query\") | mmr_retriever_semantic | (lambda docs: docs[:4]), \"query\": itemgetter(\"query\")} \n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
    ")\n",
    "\n",
    "response_dataset = await gen_rag_responses(semantic_mmr_rag_chain)\n",
    "results = evaluate(response_dataset, \n",
    "                   RAGAS_METRICS)\n",
    "\n",
    "# Check out the results\n",
    "print(results)\n",
    "results_df = pd.DataFrame([results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read test questions\n",
      "generating responses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Questions: 100%|██████████| 30/30 [01:53<00:00,  3.78s/it]\n",
      "Evaluating:  29%|██▉       | 35/120 [00:14<00:26,  3.19it/s]No statements were generated from the answer.\n",
      "Evaluating: 100%|██████████| 120/120 [00:53<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'faithfulness': 0.9345, 'answer_relevancy': 0.8475, 'context_precision': 0.8333, 'context_recall': 0.8983}\n"
     ]
    }
   ],
   "source": [
    "semantic_ensemble_rag_chain = (\n",
    "    {\"context\": itemgetter(\"query\") | ensemble_retriever_semantic | (lambda docs: docs[:4]), \"query\": itemgetter(\"query\")} \n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
    ")\n",
    "\n",
    "response_dataset = await gen_rag_responses(semantic_ensemble_rag_chain)\n",
    "results = evaluate(response_dataset, \n",
    "                   RAGAS_METRICS)\n",
    "\n",
    "# Check out the results\n",
    "print(results)\n",
    "results_df = pd.DataFrame([results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read test questions\n",
      "generating responses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Questions: 100%|██████████| 30/30 [01:46<00:00,  3.56s/it]\n",
      "Evaluating: 100%|██████████| 120/120 [00:54<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'faithfulness': 0.9335, 'answer_relevancy': 0.9111, 'context_precision': 0.8833, 'context_recall': 0.9500}\n"
     ]
    }
   ],
   "source": [
    "ensemble_retriever_similarity = EnsembleRetriever(retrievers=[similarity_retriever_semantic,similarity_retriever_fixed])\n",
    "similarity_ensemble_rag_chain = (\n",
    "    {\"context\": itemgetter(\"query\") | ensemble_retriever_similarity | (lambda docs: docs[:4]), \"query\": itemgetter(\"query\")} \n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
    ")\n",
    "\n",
    "response_dataset = await gen_rag_responses(similarity_ensemble_rag_chain)\n",
    "results = evaluate(response_dataset, \n",
    "                   RAGAS_METRICS)\n",
    "\n",
    "# Check out the results\n",
    "print(results)\n",
    "results_df = pd.DataFrame([results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fixed-size similarity retriever: {'faithfulness': 0.9507, 'answer_relevancy': 0.7835, 'context_precision': 0.8676, 'context_recall': 0.9200}\n",
    "- Fixed-size MMR retriever: {'faithfulness': 0.9091, 'answer_relevancy': 0.9486, 'context_precision': 0.8074, 'context_recall': 0.8522}\n",
    "- Fixed-size ensemble retriever: {'faithfulness': 0.9586, 'answer_relevancy': 0.8842, 'context_precision': 0.8537, 'context_recall': 0.9133}\n",
    "\n",
    "- Semantic chunking similarity retriever:  {'faithfulness': 0.9521, 'answer_relevancy': 0.8805, 'context_precision': 0.8713, 'context_recall': 0.9272}\n",
    "- Semantic chunking ensemble retriever: {'faithfulness': 0.9345, 'answer_relevancy': 0.8475, 'context_precision': 0.8333, 'context_recall': 0.8983}\n",
    "- Semantic chunking MMR retriever: {'faithfulness': 0.9500, 'answer_relevancy': 0.8781, 'context_precision': 0.8185, 'context_recall': 0.8211}\n",
    "\n",
    "- Semantic and fixed size similarity ensemble:  {'faithfulness': 0.9335, 'answer_relevancy': 0.9111, 'context_precision': 0.8833, 'context_recall': 0.9500}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synthetic-data-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
